{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crazy-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "veterinary-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load .gdb connection - NOTE: this points directory to your MSI home folder and Tier 1 storage. If the file is elsewhere you may need to do some additional directory pointing.\n",
    "gdb_path = \"nasispedonsAK.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dress-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of layers in the .gdb\n",
    "layers = fiona.listlayers(gdb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conservative-movement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   siteobsiidref        upedonid    pedrecorigin       descname taxonname  \\\n",
      "0        1882228  TNF_NFVEG_4798  USFS NRM pedon  Jennifer A Nu      None   \n",
      "1        1881710  TNF_NFVEG_4799  USFS NRM pedon  Jennifer A Nu      None   \n",
      "2        1882881  TNF_NFVEG_4800  USFS NRM pedon  Jennifer A Nu      None   \n",
      "3        1883259  TNF_NFVEG_4801  USFS NRM pedon  Jennifer A Nu      None   \n",
      "4        1882958  TNF_NFVEG_4802  USFS NRM pedon  Jennifer A Nu      None   \n",
      "\n",
      "  localphase taxclname taxonkind pedontype pedonpurpose  ...  sasexposureend  \\\n",
      "0       None      None      None      None         None  ...             NaT   \n",
      "1       None      None      None      None         None  ...             NaT   \n",
      "2       None      None      None      None         None  ...             NaT   \n",
      "3       None      None      None      None         None  ...             NaT   \n",
      "4       None      None      None      None         None  ...             NaT   \n",
      "\n",
      "  pedbiidref grpiidref              objwlupdated objuseriidref recuseriidref  \\\n",
      "0        134     44735 2022-02-14 16:06:26+00:00          1833        1833.0   \n",
      "1        134     44735 2022-02-14 16:06:26+00:00          1833        1833.0   \n",
      "2        134     44735 2022-02-14 16:06:26+00:00          1833        1833.0   \n",
      "3        134     44735 2022-02-14 16:06:26+00:00          1833        1833.0   \n",
      "4        134     44735 2022-02-14 16:06:26+00:00          1833        1833.0   \n",
      "\n",
      "               recwlupdated    peiid  \\\n",
      "0 2022-02-14 15:54:24+00:00  1567866   \n",
      "1 2022-02-14 15:53:58+00:00  1567867   \n",
      "2 2022-02-14 15:54:56+00:00  1567868   \n",
      "3 2022-02-14 15:55:14+00:00  1567869   \n",
      "4 2022-02-14 15:55:00+00:00  1567870   \n",
      "\n",
      "                              pedondescriptionreport  \\\n",
      "0  <a href=\"https://nasis.sc.egov.usda.gov/NasisR...   \n",
      "1  <a href=\"https://nasis.sc.egov.usda.gov/NasisR...   \n",
      "2  <a href=\"https://nasis.sc.egov.usda.gov/NasisR...   \n",
      "3  <a href=\"https://nasis.sc.egov.usda.gov/NasisR...   \n",
      "4  <a href=\"https://nasis.sc.egov.usda.gov/NasisR...   \n",
      "\n",
      "                      geometry  \n",
      "0  POINT (-132.01659 56.71297)  \n",
      "1  POINT (-132.01402 56.71221)  \n",
      "2  POINT (-132.01448 56.71036)  \n",
      "3  POINT (-132.01549 56.71020)  \n",
      "4  POINT (-132.01487 56.71033)  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "Index(['siteobsiidref', 'upedonid', 'pedrecorigin', 'descname', 'taxonname',\n",
      "       'localphase', 'taxclname', 'taxonkind', 'pedontype', 'pedonpurpose',\n",
      "       'pedonunit', 'labdatadescflag', 'relexpwidth', 'erocl', 'labsourceid',\n",
      "       'pedlabsampnum', 'tsectiidref', 'tsectstopnum', 'tsectinterval',\n",
      "       'rcapointnumber', 'soilreplicatenumber', 'azimuthfromplotcenter',\n",
      "       'distancefromplotcenter', 'rectangularplotlinenumber',\n",
      "       'distancefrombaseline', 'pedodermclass', 'pedodermcovind',\n",
      "       'biolcrusttypedom', 'biolcrusttypesecond', 'physcrustsubtype',\n",
      "       'crustdevcl', 'rangevegcanopytypedom', 'rangevegcanopytypesec',\n",
      "       'forestoverstoryvegtype', 'forestunderstoryvegtype',\n",
      "       'forestgroundcovvegtypedom', 'forestgroundcovvegtypesec',\n",
      "       'agronomicfeature', 'otherfeaturedescription', 'currentcropname',\n",
      "       'littercoverpct', 'residuedescription', 'pedonhydricrating',\n",
      "       'pecertstatus', 'peqcstatus', 'peqastatus', 'saspipelengthtot',\n",
      "       'saspipelengthext', 'saspipelengthunfilled', 'sascoresettlement',\n",
      "       'sascorelength', 'sascorestoragesite', 'sasexposurebegin',\n",
      "       'sasexposureend', 'pedbiidref', 'grpiidref', 'objwlupdated',\n",
      "       'objuseriidref', 'recuseriidref', 'recwlupdated', 'peiid',\n",
      "       'pedondescriptionreport', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# create an object that points to one specific layer - NOTE: here I am pointing to the \"pedon\" layer, which contains the geometry (lat lon) and many other site level variables\n",
    "pedon_gdf = gpd.read_file(gdb_path, layer=\"pedon\") \n",
    "\n",
    "# inspect the head\n",
    "print(pedon_gdf.head()) \n",
    "\n",
    "# inspect the columns\n",
    "print(pedon_gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gorgeous-glucose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   peiidref  seqnum  hzdept  hzdepb  hzthk_l  hzthk_r  hzthk_h obsmethod  \\\n",
      "0   1567867     1.0     NaN     NaN      NaN      NaN      NaN      None   \n",
      "1   1567869     1.0     0.0     8.0      NaN      NaN      NaN      None   \n",
      "2   1567869     2.0     8.0     NaN      NaN      NaN      NaN      None   \n",
      "3   1568367     5.0    10.0   120.0      NaN      NaN      NaN      None   \n",
      "4   1568367     1.0     0.0     2.0      NaN      NaN      NaN      None   \n",
      "\n",
      "  hzname  desgndisc  ... horzlatareapct_l horzlatareapct_r  horzlatareapct_h  \\\n",
      "0     Oi        NaN  ...             None             None              None   \n",
      "1   A/Bw        NaN  ...             None             None              None   \n",
      "2      C        NaN  ...             None             None              None   \n",
      "3   None        NaN  ...             None             None              None   \n",
      "4   None        NaN  ...             None             None              None   \n",
      "\n",
      "  dspcomplayerid  aashtocl  unifiedcl              recwlupdated    phiid  \\\n",
      "0           None      None       None 2022-02-08 21:14:17+00:00  7987957   \n",
      "1           None      None       None 2022-02-08 21:14:17+00:00  7987958   \n",
      "2           None      None       None 2022-02-08 21:14:17+00:00  7987959   \n",
      "3           None      None       None 2022-02-08 21:14:42+00:00  7987979   \n",
      "4           None      None       None 2022-02-08 21:14:42+00:00  7987975   \n",
      "\n",
      "   recuseriidref  geometry  \n",
      "0         2395.0      None  \n",
      "1         2395.0      None  \n",
      "2         2395.0      None  \n",
      "3         2395.0      None  \n",
      "4         2395.0      None  \n",
      "\n",
      "[5 rows x 70 columns]\n",
      "Index(['peiidref', 'seqnum', 'hzdept', 'hzdepb', 'hzthk_l', 'hzthk_r',\n",
      "       'hzthk_h', 'obsmethod', 'hzname', 'desgndisc', 'desgnmaster',\n",
      "       'desgnmasterprime', 'desgnvert', 'texture', 'stratextsflag',\n",
      "       'claytotest', 'claycarbest', 'silttotest', 'sandtotest', 'fragvoltot',\n",
      "       'horcolorvflag', 'obssoimoiststat', 'rupresblkmst', 'rupresblkdry',\n",
      "       'rupresblkcem', 'rupresplate', 'mannerfailure', 'stickiness',\n",
      "       'plasticity', 'toughclass', 'penetrres', 'penetorient', 'ksatpedon',\n",
      "       'ksatstddev', 'ksatrepnum', 'horzpermclass', 'obsinfiltrationrate',\n",
      "       'phfield', 'phdetermeth', 'effclass', 'effagent', 'carbdevstagefe',\n",
      "       'carbdevstagecf', 'mneffclass', 'mneffagent', 'reactadipyridyl',\n",
      "       'dipyridylpct', 'dipyridylloc', 'excavdifcl', 'soilodor',\n",
      "       'soilodorintensity', 'rmonosulfidep', 'h20230percentreaction',\n",
      "       'h2o23percentreaction', 'acidvolatilesulfidetest', 'bounddistinct',\n",
      "       'boundtopo', 'horzvoltotpct_l', 'horzvoltotpct_r', 'horzvoltotpct_h',\n",
      "       'horzlatareapct_l', 'horzlatareapct_r', 'horzlatareapct_h',\n",
      "       'dspcomplayerid', 'aashtocl', 'unifiedcl', 'recwlupdated', 'phiid',\n",
      "       'recuseriidref', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# create an object for the horizon table\n",
    "horizon_gdf = gpd.read_file(gdb_path, layer=\"phorizon\") \n",
    "\n",
    "# inspect the head\n",
    "print(horizon_gdf.head()) \n",
    "\n",
    "# inspect the columns\n",
    "print(horizon_gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proper-cheat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       peiidref  total_O_thickness\n",
      "0        107546                6.0\n",
      "1        107547                2.0\n",
      "2        107548                0.0\n",
      "3        107549                3.0\n",
      "4        107550               27.0\n",
      "...         ...                ...\n",
      "23214   1679621               12.0\n",
      "23215   1679622               39.0\n",
      "23216   1679623               10.0\n",
      "23217   1679624               12.0\n",
      "23218   1679625               60.0\n",
      "\n",
      "[23219 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Calculate the thickness of each horizon\n",
    "horizon_gdf['thickness'] = horizon_gdf['hzdepb'] - horizon_gdf['hzdept']\n",
    "\n",
    "# Step 2: Filter for horizons with \"O\" in the hzname\n",
    "o_horizons = horizon_gdf[horizon_gdf['hzname'].str.contains('O', na=False)]\n",
    "\n",
    "# Step 3: Group by pedon ID and sum the thickness\n",
    "total_o_thickness = o_horizons.groupby('peiidref')['thickness'].sum().reset_index()\n",
    "\n",
    "# Rename the column for clarity\n",
    "total_o_thickness.rename(columns={'thickness': 'total_O_thickness'}, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(total_o_thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-shoulder",
   "metadata": {},
   "source": [
    "#chatgpt ok - now it gets a bit more complicated. There are some pedons where the O horizon overlaps with another horizon (so for example, two horizons might look like this): peiidref, hzdept, hzdepb, hzname; 123456, 0, 10, Oi; 123456, 0, 35, C. In this case, I would like to weight the O thickness by the number of other overlapping horizons. So, for example in the case I gave, the \"normal\" sum O thickness would be 10cm. However, because there is one overlapping horizon, then it would be 5cm. I'll give a few other examples. in this case: peiidref, hzdept, hzdepb, hzname; 123456, 0, 10, Oi; 123456, 0, 35, C, 123456, 0, 20, Bw. The \"normal\" sum would be 10cm, but because there are two overlapping horizons, the adjusted sum would be 3.33...cm. Final example: peiidref, hzdept, hzdepb, hzname; 123456, 0, 10, Oi; 123456, 0, 5, Oe; 123456, 5, 10, Bw. In this case, the \"normal\" thickness would be 5cm. However, the first 5cm are overlapping O's, which would count for 5. The 5-10 depth increment is an O with a competing non-O, so the thickness for that would be 2.5. Therefore, the corrected sum would be 7.5 \n",
    "\n",
    "To address the overlapping horizons and adjust the O horizon thickness accordingly, we can break this task down into several steps:\n",
    "\n",
    "Identify Overlaps: For each O horizon, we need to determine how many other horizons overlap with it.\n",
    "Calculate Adjusted Thickness: Based on the overlaps, we will adjust the thickness of the O horizons.\n",
    "Aggregate Results: Finally, we will sum the adjusted thicknesses for each unique pedon ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accepting-harris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       peiidref  total_adjusted_O_thickness\n",
      "0        107546                         6.0\n",
      "1        107547                         2.0\n",
      "2        107548                         0.0\n",
      "3        107549                         3.0\n",
      "4        107550                        27.0\n",
      "...         ...                         ...\n",
      "23214   1679621                        12.0\n",
      "23215   1679622                        39.0\n",
      "23216   1679623                        10.0\n",
      "23217   1679624                        12.0\n",
      "23218   1679625                        60.0\n",
      "\n",
      "[23219 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have the horizon_gdf DataFrame loaded\n",
    "\n",
    "# Step 1: Calculate the thickness of each horizon\n",
    "horizon_gdf['thickness'] = horizon_gdf['hzdepb'] - horizon_gdf['hzdept']\n",
    "\n",
    "# Step 2: Filter for horizons with \"O\" in the hzname\n",
    "o_horizons = horizon_gdf[horizon_gdf['hzname'].str.contains('O', na=False)]\n",
    "\n",
    "# Step 3: Initialize a list to hold the adjusted thicknesses\n",
    "adjusted_thicknesses = []\n",
    "\n",
    "# Step 4: Loop through each O horizon and calculate adjusted thickness\n",
    "for index, o_row in o_horizons.iterrows():\n",
    "    o_start = o_row['hzdept']\n",
    "    o_end = o_row['hzdepb']\n",
    "    \n",
    "    # Get other horizons that overlap with the current O horizon\n",
    "    overlapping_horizons = horizon_gdf[\n",
    "        (horizon_gdf['peiidref'] == o_row['peiidref']) & \n",
    "        (horizon_gdf['hzdept'] < o_end) & \n",
    "        (horizon_gdf['hzdepb'] > o_start)\n",
    "    ]\n",
    "    \n",
    "    # Calculate total thickness of O horizon\n",
    "    o_thickness = o_row['thickness']\n",
    "    \n",
    "    # If there are overlapping horizons, calculate adjusted thickness\n",
    "    if not overlapping_horizons.empty:\n",
    "        overlap_count = len(overlapping_horizons)\n",
    "        # Calculate the adjusted thickness\n",
    "        adjusted_thickness = o_thickness / overlap_count\n",
    "    else:\n",
    "        adjusted_thickness = o_thickness  # No overlaps means no adjustment\n",
    "    \n",
    "    # Store the result\n",
    "    adjusted_thicknesses.append({\n",
    "        'peiidref': o_row['peiidref'],\n",
    "        'adjusted_thickness': adjusted_thickness\n",
    "    })\n",
    "\n",
    "# Step 5: Create a DataFrame from adjusted thicknesses\n",
    "adjusted_thickness_df = pd.DataFrame(adjusted_thicknesses)\n",
    "\n",
    "# Step 6: Sum adjusted thickness for each pedon ID\n",
    "final_adjusted_thickness = adjusted_thickness_df.groupby('peiidref')['adjusted_thickness'].sum().reset_index()\n",
    "\n",
    "# Rename the column for clarity\n",
    "final_adjusted_thickness.rename(columns={'adjusted_thickness': 'total_adjusted_O_thickness'}, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(final_adjusted_thickness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-consequence",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Calculate Thickness: We calculate the thickness of each horizon as before.\n",
    "Filter O Horizons: We filter for the horizons that contain \"O\".\n",
    "Loop Through O Horizons:\n",
    "For each O horizon, we check which other horizons overlap using the conditions for overlapping (the start of one horizon is less than the end of another and vice versa).\n",
    "Count the number of overlapping horizons.\n",
    "Adjust the thickness of the O horizon based on the count of overlaps.\n",
    "Store Adjusted Thickness: We append the adjusted thicknesses to a list.\n",
    "Create a DataFrame: Convert the list of adjusted thicknesses into a DataFrame.\n",
    "Aggregate Results: Finally, group by peiidref and sum the adjusted thicknesses.\n",
    "This method effectively handles the complexity of overlapping horizons and computes the desired adjusted sum for each unique pedon ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "induced-elements",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       peiidref  o_thickness_straight_sum  o_thickness_adjusted\n",
      "0        107546                       6.0                   6.0\n",
      "1        107547                       2.0                   2.0\n",
      "2        107548                       0.0                   0.0\n",
      "3        107549                       3.0                   3.0\n",
      "4        107550                      27.0                  27.0\n",
      "...         ...                       ...                   ...\n",
      "23214   1679621                      12.0                  12.0\n",
      "23215   1679622                      39.0                  39.0\n",
      "23216   1679623                      10.0                  10.0\n",
      "23217   1679624                      12.0                  12.0\n",
      "23218   1679625                      60.0                  60.0\n",
      "\n",
      "[23219 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have the horizon_gdf DataFrame loaded\n",
    "\n",
    "# Step 1: Calculate the thickness of each horizon\n",
    "horizon_gdf['thickness'] = horizon_gdf['hzdepb'] - horizon_gdf['hzdept']\n",
    "\n",
    "# Step 2: Filter for horizons with \"O\" in the hzname\n",
    "o_horizons = horizon_gdf[horizon_gdf['hzname'].str.contains('O', na=False)]\n",
    "\n",
    "# Calculate the original sum of O thicknesses\n",
    "original_thickness_sum = o_horizons.groupby('peiidref')['thickness'].sum().reset_index()\n",
    "original_thickness_sum.rename(columns={'thickness': 'o_thickness_straight_sum'}, inplace=True)\n",
    "\n",
    "# Step 3: Initialize a list to hold the adjusted thicknesses\n",
    "adjusted_thicknesses = []\n",
    "\n",
    "# Step 4: Loop through each O horizon and calculate adjusted thickness\n",
    "for index, o_row in o_horizons.iterrows():\n",
    "    o_start = o_row['hzdept']\n",
    "    o_end = o_row['hzdepb']\n",
    "    \n",
    "    # Get other horizons that overlap with the current O horizon\n",
    "    overlapping_horizons = horizon_gdf[\n",
    "        (horizon_gdf['peiidref'] == o_row['peiidref']) & \n",
    "        (horizon_gdf['hzdept'] < o_end) & \n",
    "        (horizon_gdf['hzdepb'] > o_start)\n",
    "    ]\n",
    "    \n",
    "    # Calculate total thickness of O horizon\n",
    "    o_thickness = o_row['thickness']\n",
    "    \n",
    "    # If there are overlapping horizons, calculate adjusted thickness\n",
    "    if not overlapping_horizons.empty:\n",
    "        overlap_count = len(overlapping_horizons)\n",
    "        # Calculate the adjusted thickness\n",
    "        adjusted_thickness = o_thickness / overlap_count\n",
    "    else:\n",
    "        adjusted_thickness = o_thickness  # No overlaps means no adjustment\n",
    "    \n",
    "    # Store the result\n",
    "    adjusted_thicknesses.append({\n",
    "        'peiidref': o_row['peiidref'],\n",
    "        'o_thickness_adjusted': adjusted_thickness\n",
    "    })\n",
    "\n",
    "# Step 5: Create a DataFrame from adjusted thicknesses\n",
    "adjusted_thickness_df = pd.DataFrame(adjusted_thicknesses)\n",
    "\n",
    "# Step 6: Sum adjusted thickness for each pedon ID\n",
    "final_adjusted_thickness = adjusted_thickness_df.groupby('peiidref')['o_thickness_adjusted'].sum().reset_index()\n",
    "\n",
    "# Step 7: Merge the original and adjusted thickness DataFrames\n",
    "final_result = pd.merge(original_thickness_sum, final_adjusted_thickness, on='peiidref', how='outer')\n",
    "\n",
    "# Display the final result\n",
    "print(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "serial-cookbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       peiidref  o_thickness_straight_sum  o_thickness_adjusted\n",
      "11       107559                      52.0             32.000000\n",
      "14       107563                      85.0             51.750000\n",
      "21       107570                     100.0             69.500000\n",
      "22       107571                      10.0              5.000000\n",
      "23       107572                      19.0              7.833333\n",
      "...         ...                       ...                   ...\n",
      "22913   1670036                      26.0             13.000000\n",
      "22983   1670250                      55.0             40.333333\n",
      "23005   1671806                      10.0              5.000000\n",
      "23019   1671821                      37.0             31.000000\n",
      "23078   1675602                      16.0             14.000000\n",
      "\n",
      "[172 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter for peiidref where the straight sum and adjusted sum are different\n",
    "different_values = final_result[final_result['o_thickness_straight_sum'] != final_result['o_thickness_adjusted']]\n",
    "\n",
    "# Select only the relevant columns\n",
    "different_values = different_values[['peiidref', 'o_thickness_straight_sum', 'o_thickness_adjusted']]\n",
    "\n",
    "# Display the results\n",
    "print(different_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-permission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8.3",
   "language": "python",
   "name": "python3.8.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
